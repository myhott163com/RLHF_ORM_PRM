{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcTRRC0Jvl4W"
      },
      "source": [
        "## Outcome Reward Model (MVP)\n",
        "\n",
        "Train a minimal outcome reward model by fine-tuning `Qwen3-1.7B-Base` with LoRA on GSM8K-derived correct/incorrect math answers. For each question we parse the gold numeric answer, add a small random offset to synthesize the wrong completion, then apply per-token BCE loss on completion tokens. At the end we score a fresh GSM8K test question to show how the trained model ranks a correct vs. corrupted completion it never saw during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wWSYq-Mvl4Y",
        "outputId": "b4e789a5-1167-43a0-8527-018b31e700cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q transformers datasets accelerate bitsandbytes peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "488e10680d3e4deb9638fd65c7445380"
          ]
        },
        "id": "mXA44VrSvl4Y",
        "outputId": "a8be8884-99e4-4c02-cfa7-28e1a639665a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "488e10680d3e4deb9638fd65c7445380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# connect to huggingface\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hwsn3HAvl4Z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd5vOTbqvl4Z"
      },
      "source": [
        "### Configure model and LoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgMjx0vyvl4Z"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"Qwen/Qwen3-1.7B-Base\"\n",
        "DATASET = \"gsm8k\"\n",
        "SAMPLES = 200\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LR = 5e-5\n",
        "SEED = 7\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "\n",
        "lora = LoraConfig(r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\", target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tfliq2svl4a"
      },
      "source": [
        "### Build GSM8K-derived outcome dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij0NuID1vl4a",
        "outputId": "b832b5fd-049b-4694-ed8b-91170554ddbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400\n",
            "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
            "Answer:Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
            "Natalia sold 48+24 = <<4\n"
          ]
        }
      ],
      "source": [
        "def parse_answer(text: str):\n",
        "    if \"####\" in text:\n",
        "        tail = text.split(\"####\")[-1]\n",
        "    else:\n",
        "        sentences = [seg.strip() for seg in text.strip().split(\"\\n\") if seg.strip()]\n",
        "        tail = sentences[-1] if sentences else text\n",
        "    tokens = tail.replace(\",\", \"\").split()\n",
        "    for token in reversed(tokens):\n",
        "        digits = \"\".join(ch for ch in token if ch.isdigit() or ch == \"-\")\n",
        "        if digits:\n",
        "            try:\n",
        "                return int(digits)\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def pack(prompt: str, completion: str, label: int):\n",
        "    prompt_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "    completion_ids = tokenizer(completion + tokenizer.eos_token, add_special_tokens=False)[\"input_ids\"]\n",
        "    input_ids = prompt_ids + completion_ids\n",
        "    attention = [1] * len(input_ids)\n",
        "    labels = [-100] * len(prompt_ids) + [label] * len(completion_ids)\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention, \"labels\": labels}\n",
        "\n",
        "\n",
        "def build_dataset(limit: int) -> Dataset:\n",
        "    raw = load_dataset(DATASET, \"main\", split=f\"train[:{limit}]\")\n",
        "    rows = []\n",
        "    for ex in raw:\n",
        "        question = ex[\"question\"].strip()\n",
        "        prompt = f\"Question: {question}\\nAnswer:\"\n",
        "        answer = ex[\"answer\"].strip()\n",
        "        value = parse_answer(answer)\n",
        "        if value is None:\n",
        "            continue\n",
        "        rows.append(pack(prompt, answer, 1))\n",
        "        wrong = value + random.randint(1, 9)\n",
        "        wrong_solution = answer + f\"\\nTherefore, the answer is {wrong}.\"\n",
        "        rows.append(pack(prompt, wrong_solution, 0))\n",
        "    return Dataset.from_list(rows)\n",
        "\n",
        "\n",
        "data = build_dataset(SAMPLES)\n",
        "print(len(data))\n",
        "print(tokenizer.decode(data[0][\"input_ids\"][:80]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5uA377svl4b",
        "outputId": "f21561af-fc5e-41f2-ca5c-94b4b95ab7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 2 | label 1 (correct)\n",
            "Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
            "Completion: Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
            "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
            "#### 10\n",
            "Extracted answer: 10\n",
            "------------------------------------------------------------\n",
            "Example 3 | label 0 (incorrect)\n",
            "Question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
            "Completion: Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
            "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
            "#### 10\n",
            "Therefore, the answer is 13.\n",
            "Extracted answer: 13\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# show examples\n",
        "def show_dataset_example(dataset, idx):\n",
        "    row = dataset[idx]\n",
        "    text = tokenizer.decode(row[\"input_ids\"], skip_special_tokens=True)\n",
        "    if \"Answer:\" in text:\n",
        "        prompt_part, completion_part = text.split(\"Answer:\", 1)\n",
        "    else:\n",
        "        prompt_part, completion_part = text, \"\"\n",
        "    label = int(row[\"labels\"][-1])\n",
        "    question = prompt_part.replace(\"Question:\", \"\").strip()\n",
        "    completion = completion_part.strip()\n",
        "    final_value = parse_answer(completion)\n",
        "    print(f\"Example {idx} | label {label} ({'correct' if label == 1 else 'incorrect'})\")\n",
        "    print(\"Question:\", question)\n",
        "    print(\"Completion:\", completion)\n",
        "    print(\"Extracted answer:\", final_value)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "show_dataset_example(data, 2)\n",
        "show_dataset_example(data, 3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w2yrj2-vl4b"
      },
      "source": [
        "### Batch collation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-vS7rDxvl4c"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
        "    inputs = torch.full((len(batch), max_len), tokenizer.pad_token_id, dtype=torch.long)\n",
        "    attn = torch.zeros_like(inputs)\n",
        "    labels = torch.full((len(batch), max_len), -100, dtype=torch.long)\n",
        "    for i, item in enumerate(batch):\n",
        "        length = len(item[\"input_ids\"])\n",
        "        inputs[i, :length] = torch.tensor(item[\"input_ids\"], dtype=torch.long)\n",
        "        attn[i, :length] = torch.tensor(item[\"attention_mask\"], dtype=torch.long)\n",
        "        labels[i, :length] = torch.tensor(item[\"labels\"], dtype=torch.long)\n",
        "    return {\"input_ids\": inputs, \"attention_mask\": attn, \"labels\": labels}\n",
        "\n",
        "loader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euc3Kmbnvl4c"
      },
      "source": [
        "### Define LoRA outcome reward model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAkRePslvl4c",
        "outputId": "2636637b-6173-4ec8-961b-9cec3c685256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17.434625 M trainable params\n"
          ]
        }
      ],
      "source": [
        "class OutcomeRewardModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_ID,\n",
        "            quantization_config=bnb,\n",
        "            device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "        base = prepare_model_for_kbit_training(base)\n",
        "        base.config.use_cache = False\n",
        "        self.model = get_peft_model(base, lora)\n",
        "        self.head = nn.Linear(self.model.config.hidden_size, 1, bias=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            use_cache=False,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        hidden = outputs.hidden_states[-1]\n",
        "        logits = self.head(hidden).squeeze(-1)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            mask = labels != -100\n",
        "            if mask.any():\n",
        "                loss = F.binary_cross_entropy_with_logits(logits[mask], labels[mask].float())\n",
        "            else:\n",
        "                loss = logits.sum() * 0\n",
        "        return loss, logits\n",
        "\n",
        "orm_model = OutcomeRewardModel().to(device)\n",
        "print(sum(p.numel() for p in orm_model.parameters() if p.requires_grad)/1e6, \"M trainable params\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zMBdCrtvl4c"
      },
      "source": [
        "### Train for one epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIssrp7Svl4c",
        "outputId": "4de4deb2-6050-4285-ab5b-2c96817063a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 step 0 loss 0.9715\n",
            "epoch 0 step 10 loss 1.0870\n",
            "epoch 0 step 20 loss 0.6629\n",
            "epoch 0 step 30 loss 0.8053\n",
            "epoch 0 step 40 loss 0.7621\n",
            "epoch 0 step 50 loss 0.6903\n",
            "epoch 0 step 60 loss 0.8525\n",
            "epoch 0 step 70 loss 0.6804\n",
            "epoch 0 step 80 loss 0.5791\n",
            "epoch 0 step 90 loss 0.7675\n",
            "epoch 0 loss 0.7564 acc 0.486\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, orm_model.parameters()), lr=LR)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    orm_model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_tokens = 0\n",
        "    for step, batch in enumerate(loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        loss, logits = orm_model(**batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "        mask = batch[\"labels\"] != -100\n",
        "        preds = (torch.sigmoid(logits[mask]) > 0.5).long()\n",
        "        total_correct += (preds == batch[\"labels\"][mask]).sum().item()\n",
        "        total_tokens += mask.sum().item()\n",
        "        if step % 10 == 0:\n",
        "            print(f\"epoch {epoch} step {step} loss {loss.item():.4f}\")\n",
        "    print(f\"epoch {epoch} loss {total_loss/len(loader):.4f} acc {total_correct/total_tokens:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHCxB_4yvl4d"
      },
      "source": [
        "### Score an unseen GSM8K test question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhWkSMoovl4d",
        "outputId": "7595ac6f-a303-4dd6-992f-0c3bb1a68928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: An electronics seller bought 5 phones for $700 each and gives the seller $4000 in dollar bills. How much will the seller give back in change?\n",
            "\n",
            "Completion (correct):\n",
            "The seller bought the 5 phones for $700 * 5 = $<<700*5=3500>>3500.\n",
            "So the seller gives back $4000-$3500 = $<<4000-3500=500>>500.\n",
            "#### 500\n",
            "Average token prob: 0.435\n",
            "\n",
            "Completion (incorrect):\n",
            "The seller bought the 5 phones for $700 * 5 = $<<700*5=3500>>3500.\n",
            "So the seller gives back $4000-$3500 = $<<4000-3500=500>>500.\n",
            "#### 500\n",
            "Therefore, the answer is 505.\n",
            "Average token prob: 0.379\n"
          ]
        }
      ],
      "source": [
        "def score_unseen_pair(model, seed: int = SEED):\n",
        "    test_index = random.randint(0, 1000)\n",
        "    sample = load_dataset(DATASET, \"main\", split=f\"test[{test_index}:{test_index + 1}]\")[0]\n",
        "    question = sample[\"question\"].strip()\n",
        "    prompt = f\"Question: {question}\\nAnswer:\"\n",
        "    answer = sample[\"answer\"].strip()\n",
        "    value = parse_answer(answer)\n",
        "    if value is None:\n",
        "        raise ValueError(\"Unable to parse numeric answer from GSM8K sample\")\n",
        "    wrong_value = value + random.randint(1, 9)\n",
        "    wrong_answer = answer + f\"\\nTherefore, the answer is {wrong_value}.\"\n",
        "\n",
        "    rows = [pack(prompt, answer, 1), pack(prompt, wrong_answer, 0)]\n",
        "    batch = collate(rows)\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        _, logits = model(**batch)\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "    print(\"Question:\", question)\n",
        "    for idx, row in enumerate(rows):\n",
        "        text = tokenizer.decode(row[\"input_ids\"], skip_special_tokens=True)\n",
        "        completion = text.split(\"Answer:\", 1)[-1].strip()\n",
        "        mask = batch[\"labels\"][idx] != -100\n",
        "        completion_prob = probs[idx][mask].mean().item()\n",
        "        label = \"correct\" if idx == 0 else \"incorrect\"\n",
        "        print(f\"\\nCompletion ({label}):\\n{completion}\")\n",
        "        print(f\"Average token prob: {completion_prob:.3f}\")\n",
        "\n",
        "score_unseen_pair(orm_model)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}